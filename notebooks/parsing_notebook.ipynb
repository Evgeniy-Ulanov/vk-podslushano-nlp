{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Приложение 1. Код для проектной работы. Сбор данных. Евгений Уланов, АДГО"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Парсинг данных из ВК"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Необходимые библиотеки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import requests\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подгружаем таблицу с вручную собранными группами"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['dybenko_pu35', 'pdshl6', 'lic3cheb', 'podslushano_15_kyzyl', 'podslushano130lyceum', 'podslushka_3lyceum', 'podslyshano127', 'vsev.overheard', 'echoschool22', 'irkschool39', 'bgpkpodslushano', 'school_342', 'shkola_3_zverinets', 'vsevolojsk.school4', 'school_6and4', '7school.veryverycoooool', '16schoollol', 'school242023', 'school26_pds', 'podslushano_shk26', 'school26okk', 'school228037', 'school31_mytischi', 'podslushano33ishi', 'podslushka33_ykt', 'podslushano_school33_podolsk', 'podslushano35nino', 'hot_36', 'podslyshka38', 'chelyabinsk41', 'sharagaa43', 'shigapornoanal', 'publicschool46', 'gdz_ot_putina47', 'mangetka283', 'overheard_school_51', 'podsluhano53', 'vr8682691', 'irk66school', 'ps_67', 'pod_nlo69', 'schoolnomber69', 'school72ul', 'podslushannno__75', 'krasnodar_school93', 'omsk_99', 'schl100', 'samara_102', 'demasluh', 'tsss105', 'mbousoh113', 'school_114.samara', 'podslyshano127', 'podslushano129', 'podslushano_shk131', 'podslushano141', 'podslushano_154']\n"
     ]
    }
   ],
   "source": [
    "groups = pd.read_csv('vk_groups - Sheet1.csv', delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция для сбора постов. count = 100 это максимальное количество постов, которое возможно собрать за один запрос (правило API VK). Но параметр offset помогает делать сразу несколько запросов по 100 постов. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def take_posts(groups_df):\n",
    "    token = \"\" # мой API ключ\n",
    "    version = \"5.199\" # версия API (указана в документации)\n",
    "    count = 100\n",
    "    all_posts_data = []\n",
    "\n",
    "    for index, row in groups_df.iterrows():\n",
    "        domain = row['domain_group']\n",
    "        name = row['name']\n",
    "        region = row['region']\n",
    "        \n",
    "        offset = 0\n",
    "        while offset <= 500:\n",
    "            response = requests.get('https://api.vk.com/method/wall.get',\n",
    "                                    params={\n",
    "                                        'access_token': token,\n",
    "                                        'v': version,\n",
    "                                        'domain': domain,\n",
    "                                        'count': count,\n",
    "                                        'offset': offset\n",
    "                                    })\n",
    "            data = response.json().get('response', {}).get('items', [])\n",
    "            for post in data:\n",
    "                post_data = {\n",
    "                    'name': name,\n",
    "                    'region': region,\n",
    "                    'text': post.get('text', ''),\n",
    "                    'likes': post['likes']['count'],\n",
    "                    'reposts': post['reposts']['count'],\n",
    "                    'date': pd.to_datetime(post['date'], unit='s')  # конвертируем timestamp в datetime\n",
    "                }\n",
    "                all_posts_data.append(post_data)\n",
    "            offset += 100\n",
    "            time.sleep(0.5)\n",
    "    return pd.DataFrame(all_posts_data)\n",
    "\n",
    "\n",
    "posts_df = take_posts(groups)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Некоторые группа не имели домена, а имели id. Там нужно указывать owner_id в параметрах вместо domain, подгрузим такие группы отдельно"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups_id = pd.read_csv('vk_id - Sheet1.csv', delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция для id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def take_posts_id(groups_df):\n",
    "    token = \"f38d713bf38d713bf38d713bb2f09a3d08ff38df38d713b96429019bb2b30e25b33498e\" # мой API ключ\n",
    "    version = \"5.199\" # версия API (указана в документации)\n",
    "    count = 100\n",
    "    all_posts_data = []\n",
    "\n",
    "    for index, row in groups_df.iterrows():\n",
    "        owner_id = row['owner_id']\n",
    "        name = row['name']\n",
    "        region = row['region']\n",
    "        \n",
    "        offset = 0\n",
    "        while offset <= 500:\n",
    "            response = requests.get('https://api.vk.com/method/wall.get',\n",
    "                                    params={\n",
    "                                        'access_token': token,\n",
    "                                        'v': version,\n",
    "                                        'domain': owner_id,\n",
    "                                        'count': count,\n",
    "                                        'offset': offset\n",
    "                                    })\n",
    "            data = response.json().get('response', {}).get('items', [])\n",
    "            for post in data:\n",
    "                post_data = {\n",
    "                    'name': name,\n",
    "                    'region': region,\n",
    "                    'text': post.get('text', ''),\n",
    "                    'likes': post['likes']['count'],\n",
    "                    'reposts': post['reposts']['count'],\n",
    "                    'date': pd.to_datetime(post['date'], unit='s')  # конвертируем timestamp в datetime\n",
    "                }\n",
    "                all_posts_data.append(post_data)\n",
    "            offset += 100\n",
    "            time.sleep(0.5)\n",
    "    return pd.DataFrame(all_posts_data)\n",
    "\n",
    "\n",
    "posts_df_new = take_posts_id(groups_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# объединяем два датафрейма - один с доменами, другой с id. Они ничем не отличаются\n",
    "frames = [posts_df, posts_df_new]\n",
    "df = pd.concat(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# сохраним полученный датафрейм\n",
    "df.to_csv('project_data.csv', index=False)  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
